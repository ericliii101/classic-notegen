{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8c360047-6d0f-49c9-8f72-a8c35e03ac0f",
   "metadata": {},
   "source": [
    "#### Preprocessing Setup\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a602708b-513e-49b1-be60-24cf799fff0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "curr_dir = os.getcwd()\n",
    "base_dir = os.path.dirname(curr_dir)\n",
    "%cd -q $base_dir\n",
    "!pip install -q -r requirements.txt \n",
    "%cd -q $base_dir/core/\n",
    "# Base directory: /project-noteGen\n",
    "# Current directory: /core  \n",
    "\n",
    "import numpy as np\n",
    "import csv\n",
    "import pandas as pd\n",
    "import librosa\n",
    "from scipy.io.wavfile import read as read_wav\n",
    "from scipy.io.wavfile import write as write_wav"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47562624-a899-4de9-a333-8f6285c763e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "print(torch.version.cuda)\n",
    "print(torch.cuda.is_available())\n",
    "cuda_id = torch.cuda.current_device()\n",
    "print(cuda_id)\n",
    "print(torch.cuda.get_device_name(cuda_id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7b2b572-e8e1-4bc2-b432-89ffd6c1699f",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "t = torch.cuda.get_device_properties(device).total_memory * 1e-9\n",
    "r = torch.cuda.memory_reserved(device) * 1e-9\n",
    "a = torch.cuda.memory_allocated(device) * 1e-9\n",
    "print(f\"total: {t:.2f} GB\")\n",
    "print(f\"reserved: {r:.2f} GB\")\n",
    "print(f\"used: {a:.2f} GB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c767457c-6918-44a1-aad4-7192665ef9e5",
   "metadata": {},
   "source": [
    "######\n",
    "##### Enclosed functions (stored in preprocess.py):\n",
    "> - construct_note_samples(song_raw, song_note_labels, ds_rate=None)\n",
    "> - downsample_wav(filepath, destpath, rate)\n",
    "> - get_folder_size(path)\n",
    "> - get_dataset_size()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a7f18b3-1fac-42ac-b54c-ee2bca08c27f",
   "metadata": {},
   "source": [
    "######\n",
    "#### Investigate and use wav files\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e68edb79-c276-4bd2-937e-7ac14634c7b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wav File 1727\n",
      "\n",
      "Samples per second: 44100\n",
      "\n",
      "Number of samples: (19715328,)\n",
      "\n",
      "Number of seconds: 447.0596\n",
      "\n",
      "First 30 samples at t = 10 seconds:\n",
      "[ 0.0018 -0.0011 -0.0044 -0.0079 -0.0119 -0.0168 -0.0225 -0.0291 -0.0369\n",
      " -0.0453 -0.0535 -0.0618 -0.0694 -0.0762 -0.0826 -0.0875 -0.0909 -0.093\n",
      " -0.0934 -0.0928 -0.0919 -0.0894 -0.0861 -0.0816 -0.0754 -0.069  -0.062\n",
      " -0.0547 -0.0469 -0.0389]\n",
      "\n",
      "Example piano quarter note:\n",
      "[-0.00244 -0.00244 -0.0022  ... -0.00867 -0.00873 -0.00879]\n",
      "\n",
      "Example violin quarter note:\n",
      "[-0.00974 -0.01053 -0.01138 ...  0.00049 -0.00027  0.00015]\n",
      "\n",
      "Example finale half note:\n",
      "[-0.00983 -0.00977 -0.00958 ...  0.00055  0.00061  0.00052]\n"
     ]
    }
   ],
   "source": [
    "# Investigate training song 1727.wav with numpy and scipy wav module\n",
    "\n",
    "a = read_wav(f\"{base_dir}/data/raw/train_data/1727.wav\") # Reads the wav file\n",
    "\n",
    "print(\"Wav File 1727\\n\")\n",
    "a_sample_rate = a[0]                        # Sample rate\n",
    "a_samples = np.array(a[1], dtype=float)     # Store samples (equivalent to a_samples = a[1] for this dataset)\n",
    "a_samples_shape = np.shape(a_samples)       # Count samples\n",
    "\n",
    "print(f\"Samples per second: {a_sample_rate}\\n\")\n",
    "\n",
    "print(f\"Number of samples: {a_samples_shape}\\n\")\n",
    "\n",
    "print(f\"Number of seconds: {a_samples_shape[0] * 1/a_sample_rate:.4f}\\n\")\n",
    "\n",
    "rounded_a_samples = np.round(a_samples, decimals=4)\n",
    "print(f\"First 30 samples at t = 10 seconds:\\n{rounded_a_samples[10*a_sample_rate:10*a_sample_rate+30]}\")\n",
    "\n",
    "\n",
    "# Create a wav file for a piano note's samples (Referencing 1727.csv)\n",
    "a_piano_note = a_samples[9182:62430]\n",
    "print(f\"\\nExample piano quarter note:\\n{np.round(a_piano_note, decimals=5)}\")\n",
    "save_path = f\"{base_dir}/data/general\"\n",
    "file_handle = os.path.join(save_path, \"example_piano_note.wav\")\n",
    "write_wav(file_handle, a_sample_rate, a_piano_note.astype(np.float32))    # Writes(creates) a wav file for a note\n",
    "\n",
    "# Create a wav file for a violin note's samples\n",
    "a_violin_note = a_samples[670686:722910]\n",
    "print(f\"\\nExample violin quarter note:\\n{np.round(a_violin_note, decimals=5)}\")\n",
    "save_path = f\"{base_dir}/data/general\"\n",
    "file_handle = os.path.join(save_path, \"example_violin_note.wav\")\n",
    "write_wav(file_handle, a_sample_rate, a_violin_note.astype(np.float32))\n",
    "\n",
    "# Create a wav file for the final note's samples\n",
    "a_finale_note = a_samples[19233758:19421150]\n",
    "print(f\"\\nExample finale half note:\\n{np.round(a_finale_note, decimals=5)}\")\n",
    "save_path = f\"{base_dir}/data/general\"\n",
    "file_handle = os.path.join(save_path, \"example_finale_note.wav\")\n",
    "write_wav(file_handle, a_sample_rate, a_finale_note.astype(np.float32))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2fffd97-e6f2-4c82-a8b1-7acf056feba0",
   "metadata": {},
   "source": [
    "######\n",
    "#### Investigate and use csv files\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4d01fbbe-a889-4474-95f3-7ae8af9a6890",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "LOADING #1727 IN CSV MODULE:\n",
      "start_time end_time\n",
      "9182 90078\n",
      "9182 33758\n",
      "9182 62430\n",
      "9182 202206\n",
      "9182 62430\n",
      "33758 62430\n",
      "\n",
      "IN PANDAS:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>start_time</th>\n",
       "      <th>end_time</th>\n",
       "      <th>instrument</th>\n",
       "      <th>note</th>\n",
       "      <th>start_beat</th>\n",
       "      <th>end_beat</th>\n",
       "      <th>note_value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9182</td>\n",
       "      <td>90078</td>\n",
       "      <td>43</td>\n",
       "      <td>53</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.5</td>\n",
       "      <td>Dotted Quarter</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9182</td>\n",
       "      <td>33758</td>\n",
       "      <td>42</td>\n",
       "      <td>65</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>Eighth</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9182</td>\n",
       "      <td>62430</td>\n",
       "      <td>1</td>\n",
       "      <td>69</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Quarter</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9182</td>\n",
       "      <td>202206</td>\n",
       "      <td>44</td>\n",
       "      <td>41</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>Whole</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9182</td>\n",
       "      <td>62430</td>\n",
       "      <td>1</td>\n",
       "      <td>81</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Quarter</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   start_time  end_time  instrument  note  start_beat  end_beat   \n",
       "0        9182     90078          43    53         4.0       1.5  \\\n",
       "1        9182     33758          42    65         4.0       0.5   \n",
       "2        9182     62430           1    69         4.0       1.0   \n",
       "3        9182    202206          44    41         4.0       3.5   \n",
       "4        9182     62430           1    81         4.0       1.0   \n",
       "\n",
       "       note_value  \n",
       "0  Dotted Quarter  \n",
       "1          Eighth  \n",
       "2         Quarter  \n",
       "3           Whole  \n",
       "4         Quarter  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1727's total number of notes: 6580\n",
      "Start time of the 5th note: 33758\n",
      "------[Note 5]------\n",
      "start_time     33758\n",
      "end_time       62430\n",
      "instrument        42\n",
      "note              60\n",
      "start_beat       4.5\n",
      "end_beat         0.5\n",
      "note_value    Eighth\n",
      "Name: 5, dtype: object\n",
      "\n",
      "IN NUMPY:\n",
      "\n",
      "Shape of numpy labels: (6580, 7)\n",
      "\n",
      "Note 5: [33758 62430 42 60 4.5 0.5 'Eighth']\n",
      "\n",
      "Start time: 33758   End time: 62430\n",
      "\n",
      "The average duration of 1727's notes is 0.33706 seconds\n",
      "\n",
      "The 456th Note's Samples:\n",
      "[0.02539 0.02591 0.02695 ... 0.01593 0.01532 0.0144 ]\n"
     ]
    }
   ],
   "source": [
    "# Investigate training label 1727.csv with numpy, pandas, and csv module\n",
    "\n",
    "# Read csv file using csv module\n",
    "b = csv.reader(open(f\"{base_dir}/data/raw/train_labels/1727.csv\"))\n",
    "print(\"\\nLOADING #1727 IN CSV MODULE:\")\n",
    "for i, row in enumerate(b):                                               # Print first 5 rows' starts/ends\n",
    "    #print(row)\n",
    "    print(row[0], row[1])                                       \n",
    "    if i > 5: break\n",
    "\n",
    "# Read csv file using pandas\n",
    "b_df = pd.read_csv(f\"{base_dir}/data/raw/train_labels/1727.csv\")\n",
    "print(\"\\nIN PANDAS:\")\n",
    "display(b_df.head(n=5))                                                   # Display first 5 note labels\n",
    "print(f\"1727's total number of notes: {b_df.shape[0]}\")                   # Total number of notes\n",
    "print(f\"Start time of the 5th note: {b_df.at[5, 'start_time']}\")          # Access specific column value of note\n",
    "print(f\"------[Note 5]------\\n{b_df.loc[5]}\")                             # Access specific note\n",
    "\n",
    "\n",
    "# View in numpy by converting pandas to numpy (***)\n",
    "b_np = b_df.to_numpy()\n",
    "print(\"\\nIN NUMPY:\")\n",
    "print(f\"\\nShape of numpy labels: {np.shape(b_np)}\")                       # Shape\n",
    "print(f\"\\nNote 5: {b_np[5]}\")                                             # Note row\n",
    "print(f\"\\nStart time: {b_np[5, 0]}   End time: {b_np[5, 1]}\")             # Note elements\n",
    "\n",
    "# Find average duration of notes\n",
    "average_time = np.mean((b_np[:, 1] - b_np[:, 0]) / 44100)\n",
    "print(f\"\\nThe average duration of 1727's notes is {average_time:.5f} seconds\")\n",
    "\n",
    "# Obtain samples for specific note, and generate a wav file\n",
    "a_note_456 = a_samples[b_np[455, 0]:b_np[455, 1]]                                # Access in numpy #(0+455)\n",
    "# a_note_456 = a_samples[b_df.at[455, 'start_time']:b_df.at[455, 'end_time']]    # Alternative in pandas\n",
    "print(f\"\\nThe 456th Note's Samples:\\n{np.round(a_note_456, decimals=5)}\")\n",
    "save_path = f\"{base_dir}/data/general\"\n",
    "file_handle = os.path.join(save_path, \"example_456th_note.wav\")\n",
    "write_wav(file_handle, 44100, a_note_456.astype(np.float32))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a063326-a943-442f-947f-1f0cebe86ed1",
   "metadata": {},
   "source": [
    "######\n",
    "### Construct the Note Samples for A Song\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2480acb0-87f3-4f51-8d0f-566d3385a528",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function takes the read wav and csv files for a song and constructs a list of note samples,\n",
    "# where each element of the list contains the numpy samples corresponding to a note in the song\n",
    "\n",
    "def construct_note_samples(song_raw, song_note_labels, ds_rate=None):\n",
    "    \"\"\"\n",
    "    inputs:\n",
    "        song_raw: a read wav output for a song returned by read_wav\n",
    "                    ie song_raw = read_wav(path_to_wav_file)\n",
    "        song_note_labels: a csv table for a song's notes stored as a numpy array\n",
    "                    ie song_note_labels = pd.read_csv(path_to_csv_file).to_numpy()\n",
    "        ds_rate: sampling rate if raw song has been downsampled (ie 22050), default assumes it has not\n",
    "    output:\n",
    "        song_note_samples: a numpy array of uneven numpy array objects, each of which contain the\n",
    "                           samples (from song_raw) pertaining to one note (from song_note_labels)\n",
    "    \"\"\"\n",
    "    if ds_rate is None:\n",
    "        time_factor = 1\n",
    "    else:\n",
    "        time_factor = ds_rate / 44100\n",
    "    song_raw_samples = song_raw[1]\n",
    "    song_note_timings = song_note_labels[:, 0:2] * time_factor\n",
    "\n",
    "    notes_count = np.shape(song_note_timings)[0]\n",
    "    \n",
    "    song_note_samples = [[] for i in range(notes_count)]              # The note samples to be built\n",
    "\n",
    "    for note_i in range(notes_count):\n",
    "        start_time = int(song_note_timings[note_i, 0])\n",
    "        end_time = int(song_note_timings[note_i, 1])\n",
    "        song_note_samples[note_i] = song_raw_samples[start_time:end_time]\n",
    "\n",
    "    song_note_samples = np.array(song_note_samples, dtype=object)     # Store as np.array of uneven np.arrays\n",
    "    \n",
    "    return song_note_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b360a6c6-0af7-4bc4-991d-24080da0615a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Consolidating notes samples for 6580 notes\n",
      "\n",
      "Labels of the 100th note: [525278 555998 42 60 13.5 0.5 'Eighth']\n"
     ]
    }
   ],
   "source": [
    "# Construct Note Samples for Song #1727 (1727.wav + 1727.csv)\n",
    "\n",
    "song_raw = read_wav(f\"{base_dir}/data/raw/train_data/1727.wav\")\n",
    "song_note_labels = pd.read_csv(f\"{base_dir}/data/raw/train_labels/1727.csv\").to_numpy()\n",
    "print(f\"Consolidating notes samples for {np.shape(song_note_labels)[0]} notes\")\n",
    "\n",
    "song_note_samples = construct_note_samples(song_raw, song_note_labels)\n",
    "\n",
    "\n",
    "# Assert note samples are correct\n",
    "assert np.shape(song_note_samples[2]) == np.shape(a_piano_note)\n",
    "assert np.shape(song_note_samples[121]) == np.shape(a_violin_note)\n",
    "assert np.shape(song_note_samples[455]) == np.shape(a_note_456)\n",
    "assert np.shape(song_note_samples[6579]) == np.shape(a_finale_note)\n",
    "assert np.allclose(song_note_samples[2], a_piano_note)\n",
    "assert np.allclose(song_note_samples[121], a_violin_note)\n",
    "assert np.allclose(song_note_samples[455], a_note_456)\n",
    "assert np.allclose(song_note_samples[6579], a_finale_note)\n",
    "\n",
    "# Create a wav file for the 100th note\n",
    "save_path = f\"{base_dir}/data/general\"\n",
    "file_handle = os.path.join(save_path, \"example_100th_note.wav\")\n",
    "write_wav(file_handle, 44100, song_note_samples[99].astype(np.float32))\n",
    "print(f\"\\nLabels of the 100th note: {song_note_labels[99]}\")\n",
    "\n",
    "# Save note samples in .npy format\n",
    "np.save(f\"{base_dir}/data/general/note_samples_1727.npy\", song_note_samples, allow_pickle=True)\n",
    "\n",
    "# Load note samples from .npy format\n",
    "loaded_note_samples = np.load(f\"{base_dir}/data/general/note_samples_1727.npy\", allow_pickle=True)\n",
    "\n",
    "assert np.allclose(song_note_samples[500], loaded_note_samples[500])\n",
    "assert np.allclose(song_note_samples[1000], loaded_note_samples[1000])\n",
    "assert np.allclose(song_note_samples[1500], loaded_note_samples[1500])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d7e43a7-c92b-4283-8cd8-5f85660f5514",
   "metadata": {},
   "source": [
    "######\n",
    "### Construct Note Samples for All Test Songs (Requires 0.62 GB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "593a8f99-d350-49a4-b3b7-fc8c9f16c422",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test song ids:  [1759, 1819, 2106, 2191, 2298, 2303, 2382, 2416, 2556, 2628]\n"
     ]
    }
   ],
   "source": [
    "# Construct note sample files for each song in test data\n",
    "\n",
    "test_songs_ids = os.listdir(f\"{base_dir}/data/raw/test_data/\")\n",
    "\n",
    "for i, filename in enumerate(test_songs_ids):\n",
    "    test_songs_ids[i] = int(filename[:4])                      # Gets rid of \".wav\"\n",
    "print(f\"Test song ids:  {test_songs_ids}\")\n",
    "\n",
    "for test_song in test_songs_ids:\n",
    "    test_song_raw = read_wav(f\"{base_dir}/data/raw/test_data/{test_song}.wav\")\n",
    "    test_song_note_labels = pd.read_csv(f\"{base_dir}/data/raw/test_labels/{test_song}.csv\").to_numpy()\n",
    "    test_song_note_samples = construct_note_samples(test_song_raw, test_song_note_labels)\n",
    "    np.save(f\"{base_dir}/data/numpy/test_note_samples/note_samples_{test_song}.npy\", \\\n",
    "            test_song_note_samples, allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dddee025-1663-4f11-bb6a-9e2f24403042",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look at test note samples and see if they are correct\n",
    "\n",
    "\n",
    "note_samples_2298 = np.load(f\"{base_dir}/data/numpy/test_note_samples/note_samples_2298.npy\", \\\n",
    "                            allow_pickle=True)\n",
    "song_labels_2298 = pd.read_csv(f\"{base_dir}/data/raw/test_labels/2298.csv\").to_numpy()\n",
    "song_raw_2298 = read_wav(f\"{base_dir}/data/raw/test_data/2298.wav\")\n",
    "song_samples_2298 = song_raw_2298[1]\n",
    "\n",
    "assert np.shape(note_samples_2298)[0] == np.shape(song_labels_2298)[0]\n",
    "\n",
    "# Looking at the 132nd (half) note\n",
    "trial_note_132 = note_samples_2298[131]\n",
    "actual_note_132 = song_samples_2298[song_labels_2298[131, 0]:song_labels_2298[131, 1]]\n",
    "assert np.shape(trial_note_132) == np.shape(actual_note_132)\n",
    "assert np.allclose(trial_note_132, actual_note_132)\n",
    "\n",
    "# Create a wav file for the 132nd (half) note\n",
    "write_wav(f\"{base_dir}/data/general/test_note_132_2298.wav\", 44100, trial_note_132.astype(np.float32))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b963f4bd-c6f1-4c97-98ca-82a0de448232",
   "metadata": {},
   "source": [
    "######\n",
    "### Construct Note Samples for All Train Songs** (Requires 68 GB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d4b2300c-0327-4640-8552-dcd23ce1b5cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of train songs:   320\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "' (Uncomment to Run)\\nfor train_song in train_songs_ids:\\n    train_song_raw = read_wav(f\"{base_dir}/data/raw/train_data/{train_song}.wav\")\\n    train_song_note_labels = pd.read_csv(f\"{base_dir}/data/raw/train_labels/{train_song}.csv\").to_numpy()\\n    train_song_note_samples = construct_note_samples(train_song_raw, train_song_note_labels)\\n    np.save(f\"{base_dir}/data/numpy/train_note_samples/note_samples_{train_song}.npy\",             train_song_note_samples, allow_pickle=True)\\n'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Construct note sample files for each song in train data\n",
    "\n",
    "train_songs_ids = os.listdir(f\"{base_dir}/data/raw/train_data/\")\n",
    "\n",
    "for i, filename in enumerate(train_songs_ids):\n",
    "    train_songs_ids[i] = int(filename[:4])\n",
    "print(f\"Number of train songs:   {len(train_songs_ids)}\")\\\n",
    "\n",
    "\"\"\" (Uncomment to Run)\n",
    "for train_song in train_songs_ids:\n",
    "    train_song_raw = read_wav(f\"{base_dir}/data/raw/train_data/{train_song}.wav\")\n",
    "    train_song_note_labels = pd.read_csv(f\"{base_dir}/data/raw/train_labels/{train_song}.csv\").to_numpy()\n",
    "    train_song_note_samples = construct_note_samples(train_song_raw, train_song_note_labels)\n",
    "    np.save(f\"{base_dir}/data/numpy/train_note_samples/note_samples_{train_song}.npy\", \\\n",
    "            train_song_note_samples, allow_pickle=True)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00e776c0-090b-4b22-ba09-c7a4d5e53d53",
   "metadata": {},
   "source": [
    "***\n",
    "#### Size of datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0a8a58b4-0d64-41f1-8387-86096d7980e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gets the size of the files in one directory\n",
    "def get_folder_size(path):\n",
    "    \"\"\"\n",
    "    inputs:\n",
    "        path: the path to the directory for which get the size\n",
    "    outputs:\n",
    "        size_gb: size of files in the directory in gigabytes\n",
    "    \"\"\"\n",
    "    size_b = 0\n",
    "    for filename in os.listdir(path):\n",
    "        size_b += os.path.getsize(f\"{path}/{filename}\")\n",
    "    size_gb = size_b * 10**(-9)\n",
    "    \n",
    "    return size_gb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d1d0f840-095f-492a-ae26-9dd89434c753",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prints dataset sizes for various directories\n",
    "def get_dataset_size():\n",
    "    test_wav_songs_size = get_folder_size(f\"{base_dir}/data/raw/test_data/\")\n",
    "    train_wav_songs_size = get_folder_size(f\"{base_dir}/data/raw/train_data/\")\n",
    "\n",
    "    test_csv_songs_size = get_folder_size(f\"{base_dir}/data/raw/test_labels/\")\n",
    "    train_csv_songs_size = get_folder_size(f\"{base_dir}/data/raw/train_labels/\")\n",
    "\n",
    "    test_note_samples_size = get_folder_size(f\"{base_dir}/data/numpy/test_note_samples/\")\n",
    "    train_note_samples_size = get_folder_size(f\"{base_dir}/data/numpy/train_note_samples/\")\n",
    "\n",
    "    dataset_size = test_wav_songs_size + train_wav_songs_size + test_csv_songs_size + \\\n",
    "                    train_csv_songs_size + test_note_samples_size + train_note_samples_size\n",
    "    print(f\"test raw data:  {test_wav_songs_size:.4f} GB\")\n",
    "    print(f\"train raw data:  {train_wav_songs_size:.4f} GB\")\n",
    "    print(f\"test labels:  {test_csv_songs_size:.4f} GB\")\n",
    "    print(f\"train labels:  {test_csv_songs_size:.4f} GB\")\n",
    "    print()\n",
    "    print(f\"test note samples:  {test_note_samples_size:.4f} GB\")\n",
    "    print(f\"train note samples:  {train_note_samples_size:.4f} GB\")\n",
    "    print()\n",
    "    print(f\"dataset current total:  {dataset_size:.4f} GB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8a368174-edbd-4b4f-8ed4-98bff6108760",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test raw data:  0.2613 GB\n",
      "train raw data:  21.4128 GB\n",
      "test labels:  0.0006 GB\n",
      "train labels:  0.0006 GB\n",
      "\n",
      "test note samples:  0.6237 GB\n",
      "train note samples:  0.0000 GB\n",
      "\n",
      "dataset current total:  22.3526 GB\n"
     ]
    }
   ],
   "source": [
    "get_dataset_size()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7969866e-a58e-4736-9680-95430e1982bc",
   "metadata": {},
   "source": [
    "####\n",
    "#### Accounting for size:\n",
    "The size of the constructed note samples are on average 3x the size of the songs themselves, perhaps indicating at each moment in a song, 3 notes co-occur on average. However, this varies widely by the composition category: solo, trio, quintent, quartet, sextet...\n",
    "\n",
    "For a ~20 GB dataset of raw songs and csv labels, transforming all songs into note samples will produce ~60-70 GB.\n",
    "\n",
    "The dataset size of note samples can be reduced by 1) Choosing a select number of songs to train, 2) Choosing a select number of notes per song to construct, and 3) Downsampling the songs.\n",
    "\n",
    "Downsampling reduces the size of the raw songs, which in turn reduces the size of the constructed note samples. Downsampling is performed by sampling the original file at a lower sampling rate, and storing the result by its new sample rate.\n",
    "\n",
    "Downsampling also requires adjusting the timestep columns in train_labels and test_labels, which assume 44100kHz sampling. The function \"construct_note_samples\" performs the adjustment by taking an optional downsampling rate and calculating a time factor."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2734b55-f877-4fdb-ac70-e1991f9df8ba",
   "metadata": {},
   "source": [
    "***\n",
    "### Downsampling a song with Librosa and Scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a5a95eb9-24b9-470a-bdfe-97b374aea1cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# How to Downsample:\n",
    "# 1) Load in from librosa in desired sample rate        Sample wav file at that rate\n",
    "# 2) Write out with scipy in matching sample rate       Expand samples by that rate\n",
    "\n",
    "def downsample_wav(filepath, destpath, rate):\n",
    "    \"\"\"\n",
    "    inputs:\n",
    "        filepath: path to the wav file to be downsampled\n",
    "        destpath: path and name to store the downsampled wav file\n",
    "        rate: the downsampling rate\n",
    "    outputs:\n",
    "        downsampled_raw: the read wav output for the downsampled file\n",
    "        downsampled_size: the size of the downsampled file\n",
    "    \"\"\"\n",
    "    rate = int(rate)\n",
    "    y = librosa.load(filepath, sr=rate)[0]\n",
    "    write_wav(destpath, rate=rate, data=y)\n",
    "    downsampled_raw = read_wav(destpath)\n",
    "    downsampled_size = os.path.getsize(destpath)\n",
    "    return downsampled_raw, downsampled_size"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "598e68de-c5ca-49ab-bcd7-53bd9fb23c83",
   "metadata": {},
   "source": [
    "######\n",
    "#### Quality and Size of downsampled songs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6b0ac621-c6d1-44d3-8beb-907492dc1e29",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nOriginal size:         78.861 MB\\nDownsampled x2 size:   39.431 MB\\nDownsampled x4 size:   19.715 MB\\n'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Downsampling song 1727 (Piano Quintet)\n",
    "\"\"\"\n",
    "path_1727 = f\"{base_dir}/data/raw/train_data/1727.wav\"\n",
    "dest_dir = f\"{base_dir}/data/downsampling_comparisons/\"\n",
    "\n",
    "y_1x, size_1x = downsample_wav(path_1727, f\"{dest_dir}/1727_downsampled_0x.wav\", 44100)\n",
    "y_2x, size_2x = downsample_wav(path_1727, f\"{dest_dir}/1727_downsampled_2x.wav\", 44100 / 2)\n",
    "y_4x, size_4x = downsample_wav(path_1727, f\"{dest_dir}/1727_downsampled_4x.wav\", 44100 / 4)\n",
    "\n",
    "print(f\"Original size:         {size_1x*10**-6:.3f} MB\")\n",
    "print(f\"Downsampled x2 size:   {size_2x*10**-6:.3f} MB\")           # Minor difference in audio\n",
    "print(f\"Downsampled x4 size:   {size_4x*10**-6:.3f} MB\")           # Sizable difference in audio\n",
    "\"\"\"\n",
    "\"\"\"\n",
    "Original size:         78.861 MB\n",
    "Downsampled x2 size:   39.431 MB\n",
    "Downsampled x4 size:   19.715 MB\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4ecfc7ca-bb55-44e6-82f4-f6ada67ece45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original size:         21.307 MB\n",
      "Downsampled x2 size:   10.654 MB\n",
      "Downsampled x3 size:   7.103 MB\n"
     ]
    }
   ],
   "source": [
    "# Downsampling song 2208 (Solo Piano)\n",
    "path_2208 = f\"{base_dir}/data/raw/train_data/2208.wav\"\n",
    "dest_dir = f\"{base_dir}/data/downsampling_comparisons/\"\n",
    "\n",
    "y_1x, size_1x = downsample_wav(path_2208, f\"{dest_dir}/2208_downsampled_0x.wav\", 44100)\n",
    "y_2x, size_2x = downsample_wav(path_2208, f\"{dest_dir}/2208_downsampled_2x.wav\", 44100 / 2)\n",
    "y_3x, size_3x = downsample_wav(path_2208, f\"{dest_dir}/2208_downsampled_3x.wav\", 44100 / 3)\n",
    "\n",
    "print(f\"Original size:         {size_1x*10**-6:.3f} MB\")\n",
    "print(f\"Downsampled x2 size:   {size_2x*10**-6:.3f} MB\")           # Minimal difference in audio          \n",
    "print(f\"Downsampled x3 size:   {size_3x*10**-6:.3f} MB\")           # Minor difference in audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ff4f80d9-18c6-4b53-95a1-db6c0fd78c39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original size:         37.813 MB\n",
      "Downsampled x2 size:   18.907 MB\n",
      "Downsampled x3 size:   12.604 MB\n"
     ]
    }
   ],
   "source": [
    "# Downsampling song 2244 (Solo Violin)\n",
    "path_2244 = f\"{base_dir}/data/raw/train_data/2244.wav\"\n",
    "\n",
    "y_1x, size_1x = downsample_wav(path_2244, f\"{dest_dir}/2244_downsampled_0x.wav\", 44100)\n",
    "y_2x, size_2x = downsample_wav(path_2244, f\"{dest_dir}/2244_downsampled_2x.wav\", 44100 / 2)\n",
    "y_3x, size_3x = downsample_wav(path_2244, f\"{dest_dir}/2244_downsampled_3x.wav\", 44100 / 3)\n",
    "\n",
    "print(f\"Original size:         {size_1x*10**-6:.3f} MB\")\n",
    "print(f\"Downsampled x2 size:   {size_2x*10**-6:.3f} MB\")           # Moderate difference in audio       \n",
    "print(f\"Downsampled x3 size:   {size_3x*10**-6:.3f} MB\")           # Large difference in audio"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b17e8366-6eb1-4ba4-84c7-b5ba0ad3f50b",
   "metadata": {},
   "source": [
    "######\n",
    "#### How does downsampling affect constructed note samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8115b302-9608-4bda-9546-217f24657587",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original note samples:         38.705 MB\n",
      "Downsampled x2 note samples:   19.399 MB\n",
      "Downsampled x3 note samples:   12.964 MB\n",
      "\n",
      "Size of the note samples depend on the number of notes : the more overlapping notes, the larger\n",
      "    For solos like 2244,     size(note_samples.npy) ≈ size(raw_song.wav)\n",
      "    For quintets like 1727,  size(note_samples.npy) >> size(raw_song.wav)\n"
     ]
    }
   ],
   "source": [
    "# Comparing size of downsampled note samples for 2244\n",
    "\n",
    "labels_2244 = pd.read_csv(f\"{base_dir}/data/raw/train_labels/2244.csv\").to_numpy()\n",
    "\n",
    "note_samples_2244_0x = construct_note_samples(y_1x, labels_2244)\n",
    "note_samples_2244_2x = construct_note_samples(y_2x, labels_2244, ds_rate=44100 / 2)\n",
    "note_samples_2244_3x = construct_note_samples(y_3x, labels_2244, ds_rate=44100 / 3)\n",
    "np.save(f\"{dest_dir}/note_samples_2244_0x.npy\", note_samples_2244_0x, allow_pickle=True)\n",
    "np.save(f\"{dest_dir}/note_samples_2244_2x.npy\", note_samples_2244_2x, allow_pickle=True)\n",
    "np.save(f\"{dest_dir}/note_samples_2244_3x.npy\", note_samples_2244_3x, allow_pickle=True)\n",
    "\n",
    "size_1x = os.path.getsize(f\"{dest_dir}/note_samples_2244_0x.npy\")\n",
    "size_2x = os.path.getsize(f\"{dest_dir}/note_samples_2244_2x.npy\")\n",
    "size_3x = os.path.getsize(f\"{dest_dir}/note_samples_2244_3x.npy\")\n",
    "\n",
    "print(f\"Original note samples:         {size_1x*10**-6:.3f} MB\")\n",
    "print(f\"Downsampled x2 note samples:   {size_2x*10**-6:.3f} MB\")                   \n",
    "print(f\"Downsampled x3 note samples:   {size_3x*10**-6:.3f} MB\")\n",
    "\n",
    "print(\"\\nSize of the note samples depend on the number of notes : the more overlapping notes, the larger\")\n",
    "print(\"    For solos like 2244,     size(note_samples.npy) ≈ size(raw_song.wav)\")\n",
    "print(\"    For quintets like 1727,  size(note_samples.npy) >> size(raw_song.wav)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5f9709c2-1907-4042-bb51-e9a0ab968e62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5120 samples\n",
      "2560 samples\n",
      "1707 samples\n"
     ]
    }
   ],
   "source": [
    "# Compare quality of individual downsampled notes for 2244\n",
    "\n",
    "write_wav(f\"{dest_dir}/2244_single_high_note_0x.wav\", 44100, note_samples_2244_0x[48])\n",
    "write_wav(f\"{dest_dir}/2244_single_high_note_2x.wav\", int(44100 / 2), note_samples_2244_2x[48])\n",
    "write_wav(f\"{dest_dir}/2244_single_high_note_3x.wav\", int(44100 / 3), note_samples_2244_3x[48])\n",
    "\n",
    "# Sound virtually identical on a per note basis despite difference in samples:\n",
    "print(note_samples_2244_0x[48].size, \"samples\")\n",
    "print(note_samples_2244_2x[48].size, \"samples\")\n",
    "print(note_samples_2244_3x[48].size, \"samples\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60aabe23-5c45-4696-9674-2213c4c777bc",
   "metadata": {},
   "source": [
    "#####\n",
    "#### Average number of samples and storage size per note"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "81018ecf-1372-48d7-8f64-04eb036ed5f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average samples per note: 15659\n",
      "Average size of one note: 0.063 MB\n",
      "\n",
      "Range of pitches: [21, 104]\n"
     ]
    }
   ],
   "source": [
    "total_samples = 0\n",
    "total_notes = 0\n",
    "\n",
    "all_test_label_names = os.listdir(f\"{base_dir}/data/raw/test_labels\")\n",
    "all_train_label_names = os.listdir(f\"{base_dir}/data/raw/train_labels\")\n",
    "\n",
    "pitches = [np.inf, -np.inf]\n",
    "\n",
    "for test_label_name in all_test_label_names:\n",
    "    if test_label_name.endswith(\".csv\"):\n",
    "        test_label = pd.read_csv(f\"{base_dir}/data/raw/test_labels/{test_label_name}\").to_numpy()\n",
    "        total_samples += np.sum(test_label[:, 1] - test_label[:, 0])\n",
    "        total_notes += np.shape(test_label)[0]\n",
    "        if np.min(test_label[:, 3]) < pitches[0]: pitches[0] = np.min(test_label[:, 3])\n",
    "        if np.max(test_label[:, 3]) > pitches[1]: pitches[1] = np.max(test_label[:, 3])\n",
    "\n",
    "for train_label_name in all_train_label_names:\n",
    "    if train_label_name.endswith(\".csv\"):\n",
    "        train_label = pd.read_csv(f\"{base_dir}/data/raw/train_labels/{train_label_name}\").to_numpy()\n",
    "        total_samples += np.sum(train_label[:, 1] - train_label[:, 0])\n",
    "        total_notes += np.shape(train_label)[0]\n",
    "        if np.min(train_label[:, 3]) < pitches[0]: pitches[0] = np.min(train_label[:, 3])\n",
    "        if np.max(train_label[:, 3]) > pitches[1]: pitches[1] = np.max(train_label[:, 3])\n",
    "    \n",
    "avg_samples_per_note = total_samples / total_notes\n",
    "avg_size_per_note = avg_samples_per_note * 4 * 10**-6                 # 4 bytes per sample (float32)\n",
    "print(f\"Average samples per note: {avg_samples_per_note:.0f}\")\n",
    "print(f\"Average size of one note: {avg_size_per_note:.3f} MB\")\n",
    "\n",
    "print(f\"\\nRange of pitches: {pitches}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
